{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3903ab9",
   "metadata": {},
   "source": [
    "# Introduction au Framework Agents SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95fc3e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "llm_model = \"gpt-4.1-nano\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc0edc6",
   "metadata": {},
   "source": [
    "## Un premier agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57f026a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function calls itself,  \n",
      "Endless loop within the code—  \n",
      "Self-reference dances.\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, Runner\n",
    "\n",
    "agent = Agent(\n",
    "    model = llm_model,\n",
    "    name=\"Assistant\",\n",
    "    instructions=\"You are a helpful assistant\"\n",
    "    )\n",
    "\n",
    "result = await Runner.run(agent, \"Write a haiku about recursion in programming.\")\n",
    "print(result.final_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9536488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunResult:\n",
      "- Last agent: Agent(name=\"Assistant\", ...)\n",
      "- Final output (str):\n",
      "    Function calls itself,  \n",
      "    Endless loop within the code—  \n",
      "    Self-reference dances.\n",
      "- 1 new item(s)\n",
      "- 1 raw response(s)\n",
      "- 0 input guardrail result(s)\n",
      "- 0 output guardrail result(s)\n",
      "(See `RunResult` for more details)\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34f6bbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MessageOutputItem(agent=Agent(name='Assistant', instructions='You are a helpful assistant', handoff_description=None, handoffs=[], model='gpt-4.1-nano', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseOutputMessage(id='msg_683579529f648191badd6ce64d8706410db74986cd44289b', content=[ResponseOutputText(annotations=[], text='Function calls itself,  \\nEndless loop within the code—  \\nSelf-reference dances.', type='output_text')], role='assistant', status='completed', type='message'), type='message_output_item')\n"
     ]
    }
   ],
   "source": [
    "print(result.new_items[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd46108",
   "metadata": {},
   "source": [
    "## Mise en place de traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3a4937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import trace\n",
    "\n",
    "async def main():\n",
    "    agent = Agent(model = llm_model, name=\"Assistant\", instructions=\"Reply very concisely.\")\n",
    "\n",
    "    with trace(workflow_name=\"Conversation\"):\n",
    "        # First turn\n",
    "        result = await Runner.run(agent, \"What city is the Golden Gate Bridge in?\")\n",
    "        print(result.final_output)\n",
    "        # San Francisco\n",
    "\n",
    "        # Second turn\n",
    "        new_input = result.to_input_list() + [{\"role\": \"user\", \"content\": \"What state is it in?\"}]\n",
    "        result = await Runner.run(agent, new_input)\n",
    "        print(result.final_output)\n",
    "        # California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "143f292e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "San Francisco\n",
      "California\n"
     ]
    }
   ],
   "source": [
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-labs-49S0xQV9-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
